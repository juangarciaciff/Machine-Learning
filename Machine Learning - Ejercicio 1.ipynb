{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Ejercicios Aprendizaje Automático."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "- Autor: Juan A. García Cuevas\n",
    "- Fecha: 01/10/2016\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerías principales y configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt4Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# Importamos algunas librerías\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# Configuramos Jupyter para que los gráficos se incrusten en el notebook\n",
    "%pylab\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 1. Reglas de asociación\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enunciado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el “groceries.csv” contiene las transacciones recogidas durante un mes en una tienda de comestibles. En cada una de las filas de este archivo se encuentran los artículos comprados de forma conjunta por los diferentes clientes. Obtener las lista de artículos que tiene un soporte mínimo de 0,15. Obtener también las reglas de asociación que se pueden deducir de este conjunto de datos con un soporte mínimo de 0,05 y confianza de 0,25."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Cargamos los datos del fichero CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los datos se cargan en la variable: groceries\n",
      "La variable titanic es de tipo:  <type 'list'>\n",
      "La variable titanic tiene 9835 filas (tickets).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['citrus fruit', 'semi-finished bread', 'margarine', 'ready soups'],\n",
       " ['tropical fruit', 'yogurt', 'coffee'],\n",
       " ['whole milk'],\n",
       " ['pip fruit', 'yogurt', 'cream cheese ', 'meat spreads'],\n",
       " ['other vegetables',\n",
       "  'whole milk',\n",
       "  'condensed milk',\n",
       "  'long life bakery product'],\n",
       " ['whole milk', 'butter', 'yogurt', 'rice', 'abrasive cleaner'],\n",
       " ['rolls/buns'],\n",
       " ['other vegetables',\n",
       "  'UHT-milk',\n",
       "  'rolls/buns',\n",
       "  'bottled beer',\n",
       "  'liquor (appetizer)'],\n",
       " ['pot plants'],\n",
       " ['whole milk', 'cereals']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos el fichero CSV con los datos de tickets\n",
    "groceries = []\n",
    "groceries_file = csv.reader(open(\"data/groceries.csv\", \"rb\"))\n",
    "for row in groceries_file:\n",
    "    groceries.append(row)\n",
    "\n",
    "print 'Los datos se cargan en la variable: groceries'\n",
    "print 'La variable titanic es de tipo: ', type(groceries)\n",
    "print 'La variable titanic tiene', len(groceries), \"filas (tickets).\"\n",
    "groceries[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Obtenemos la lista de artículos que tiene un soporte mínimo de 0,15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{soda}:  sup = 0.174\n",
      "{whole milk}:  sup = 0.256\n",
      "{other vegetables}:  sup = 0.193\n",
      "{rolls/buns}:  sup = 0.184\n"
     ]
    }
   ],
   "source": [
    "# Importamos la librería apriori.py (descargada previamente de la url sugerida en el enunciado del ejercicio)\n",
    "import apriori\n",
    "\n",
    "# Ejecutamos el algoritmo apriori para obtener los k-items frecuentes (F) y el soporte de cada uno de ellos\n",
    "F, soporte = apriori.apriori(groceries, min_support=0.15, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, los articulos que aparecen en un 15% de los tickets (soporte de 0,15) son :soda, whole Milk, other vegetables y rolls/buns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Obtenemos las reglas de asociación que se pueden deducir de este conjunto de datos con un soporte mínimo de 0,05 y confianza de 0,25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{citrus fruit}:  sup = 0.083\n",
      "{curd}:  sup = 0.053\n",
      "{root vegetables}:  sup = 0.109\n",
      "{shopping bags}:  sup = 0.099\n",
      "{bottled beer}:  sup = 0.081\n",
      "{butter}:  sup = 0.055\n",
      "{newspapers}:  sup = 0.08\n",
      "{napkins}:  sup = 0.052\n",
      "{pip fruit}:  sup = 0.076\n",
      "{domestic eggs}:  sup = 0.063\n",
      "{bottled water}:  sup = 0.111\n",
      "{tropical fruit}:  sup = 0.105\n",
      "{soda}:  sup = 0.174\n",
      "{whole milk}:  sup = 0.256\n",
      "{other vegetables}:  sup = 0.193\n",
      "{canned beer}:  sup = 0.078\n",
      "{frankfurter}:  sup = 0.059\n",
      "{sausage}:  sup = 0.094\n",
      "{yogurt}:  sup = 0.14\n",
      "{pastry}:  sup = 0.089\n",
      "{margarine}:  sup = 0.059\n",
      "{coffee}:  sup = 0.058\n",
      "{brown bread}:  sup = 0.065\n",
      "{fruit/vegetable juice}:  sup = 0.072\n",
      "{whipped/sour cream}:  sup = 0.072\n",
      "{pork}:  sup = 0.058\n",
      "{rolls/buns}:  sup = 0.184\n",
      "{beef}:  sup = 0.052\n",
      "{whole milk, yogurt}:  sup = 0.056\n",
      "{whole milk, rolls/buns}:  sup = 0.057\n",
      "{whole milk, other vegetables}:  sup = 0.075\n"
     ]
    }
   ],
   "source": [
    "# Primero calculamos el soporte mínimo de 0,05\n",
    "F, soporte = apriori.apriori(groceries, min_support=0.05, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la lista anterior se muestran los artículos y grupos de artículos que aparecen en más del 5% de los tickets. Como vemos, son muy pocas las combinaciones de más de un artículo, tan solo la leche, que es el artículo más comprado con el 25,6% de las veces, aparece junto a otros artículos como yogourt, bollería y verduras. Con un soperte más bajo aparecerían más artículos y combinaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{yogurt} ---> {whole milk}:  conf = 0.402, sup = 0.056\n",
      "{rolls/buns} ---> {whole milk}:  conf = 0.308, sup = 0.057\n",
      "{other vegetables} ---> {whole milk}:  conf = 0.387, sup = 0.075\n",
      "{whole milk} ---> {other vegetables}:  conf = 0.293, sup = 0.075\n"
     ]
    }
   ],
   "source": [
    "# A continuación calculamos las reglas de asociación con una confianza de 0,25.\n",
    "H1 = apriori.generate_rules(F, soporte, min_confidence=0.25, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De los datos podemos resolver lo siguiente:\n",
    "\n",
    "- Más del 40% de las veces que se compra yogurt también se compra leche, y aparece en el 5,6% de los tickets.\n",
    "- Casi el 31% de las veces que se compra bollería también se compra leche, y aparece en el 5,7% de los tickets.\n",
    "- Casi el 39% de las veces que se compra verdura también se compra leche, y aparece en el 7,5% de los tickets.\n",
    "- Más del 29% de las veces que se compra leche también se compra verdura, y aparece en el 7,5% de los tickets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 2. Implementación de una regresión “stepwise” con eliminación hacia atrás\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enunciado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando como referencia el código del algoritmo “stepwise” con selección hacia adelante (Fordward Stepwise Regression) que se encuentra en el archivo “CIF005_02_06_Stepwise.ipynb” realizar una implementación del del algoritmo con eliminación hacia atrás (Backward Stepwise Regression). En este caso la selección de las variables se realiza empezando con un modelo que utiliza todas la variables disponibles para ir eliminando en cada paso la que produce el modelo menos significativo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Fordward Stepwise Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_regression(x, y):\n",
    "    # Obtencion del conjunto de datos para validación\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "\n",
    "    # Modelo para realizar los ajustes\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Variable para almacenar los índices de la lista de atributos usados\n",
    "    feature_list = list(x.columns)\n",
    "    feature_order = []\n",
    "    feature_error = []\n",
    "    feature_names = []\n",
    "\n",
    "    # Iteración sobre todas las variables\n",
    "    for i in range(len(feature_list)):\n",
    "        idx_try = [val for val in range(len(feature_list)) if val not in feature_order]\n",
    "        iter_error = []\n",
    "\n",
    "        for i_try in idx_try:\n",
    "            useRow = feature_order[:]\n",
    "            useRow.append(i_try)\n",
    "\n",
    "            use_train = x_train[x_train.columns[useRow]]\n",
    "            use_test = x_test[x_train.columns[useRow]]\n",
    "\n",
    "            model.fit(use_train, y_train)\n",
    "            rmsError = numpy.linalg.norm((y_test - model.predict(use_test)), 2)/sqrt(len(y_test))\n",
    "            iter_error.append(rmsError)\n",
    "\n",
    "        # Guardamos la posicion de la combinacion con el menor error\n",
    "        pos_best = numpy.argmin(iter_error)\n",
    "        \n",
    "        if len(feature_error) == 0 or (iter_error[pos_best] < feature_error[-1]):\n",
    "            feature_order.append(idx_try[pos_best])\n",
    "            feature_error.append(iter_error[pos_best])\n",
    "            feature_names.append(feature_list[idx_try[pos_best]])\n",
    "            print \"Paso\", len(feature_error), \"variable\", feature_list[idx_try[pos_best]], \"con RMS\", iter_error[pos_best]\n",
    "        else:\n",
    "            return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Backward Stepwise Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def backward_regression(x, y):\n",
    "    # Obtencion del conjunto de datos para validación\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "\n",
    "    # Modelo para realizar los ajustes\n",
    "    model = LinearRegression()\n",
    "\n",
    "    feature_order = range(len(features))\n",
    "    feature_error = []\n",
    "    feature_range = []\n",
    "\n",
    "    for i in range(len(features)-1):\n",
    "        idx_try = [val for val in range(len(features)) if val in feature_order]\n",
    "        iter_error = []\n",
    "\n",
    "        for i_try in idx_try:\n",
    "            useRow = feature_order[:]\n",
    "            useRow.remove(i_try)\n",
    "\n",
    "            use_train = x_train[x_train.columns[useRow]]\n",
    "            use_test = x_test[x_train.columns[useRow]]\n",
    "\n",
    "            model.fit(use_train, y_train)\n",
    "            rmsError = numpy.linalg.norm((y_test - model.predict(use_test)), 2)/math.sqrt(len(y_test))\n",
    "            iter_error.append(rmsError)\n",
    "\n",
    "        pos_best = numpy.argmin(iter_error)\n",
    "        feature_order.remove(idx_try[pos_best])\n",
    "        feature_range.append(idx_try[pos_best])\n",
    "        feature_error.append(iter_error[pos_best])\n",
    "\n",
    "    for i in range(len(features)-1):\n",
    "        print \"En el paso\", i, \"se ha eliminado la varible\", features[feature_range[i]], \"con un error\", feature_error[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Para probar las dos funciones de regresión cargaremos el conjunto de datos de calidad de los vinos utilizado en clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.854788</td>\n",
       "      <td>0.278241</td>\n",
       "      <td>0.334192</td>\n",
       "      <td>6.391415</td>\n",
       "      <td>0.045772</td>\n",
       "      <td>35.308085</td>\n",
       "      <td>138.360657</td>\n",
       "      <td>0.994027</td>\n",
       "      <td>3.188267</td>\n",
       "      <td>0.489847</td>\n",
       "      <td>10.514267</td>\n",
       "      <td>5.877909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.843868</td>\n",
       "      <td>0.100795</td>\n",
       "      <td>0.121020</td>\n",
       "      <td>5.072058</td>\n",
       "      <td>0.021848</td>\n",
       "      <td>17.007137</td>\n",
       "      <td>42.498065</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>0.151001</td>\n",
       "      <td>0.114126</td>\n",
       "      <td>1.230621</td>\n",
       "      <td>0.885639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.800000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.987110</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.300000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>0.991723</td>\n",
       "      <td>3.090000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.800000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>0.043000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>0.993740</td>\n",
       "      <td>3.180000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>10.400000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.300000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>0.996100</td>\n",
       "      <td>3.280000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>11.400000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.200000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>65.800000</td>\n",
       "      <td>0.346000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>1.038980</td>\n",
       "      <td>3.820000</td>\n",
       "      <td>1.080000</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    4898.000000       4898.000000  4898.000000     4898.000000   \n",
       "mean        6.854788          0.278241     0.334192        6.391415   \n",
       "std         0.843868          0.100795     0.121020        5.072058   \n",
       "min         3.800000          0.080000     0.000000        0.600000   \n",
       "25%         6.300000          0.210000     0.270000        1.700000   \n",
       "50%         6.800000          0.260000     0.320000        5.200000   \n",
       "75%         7.300000          0.320000     0.390000        9.900000   \n",
       "max        14.200000          1.100000     1.660000       65.800000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  4898.000000          4898.000000           4898.000000  4898.000000   \n",
       "mean      0.045772            35.308085            138.360657     0.994027   \n",
       "std       0.021848            17.007137             42.498065     0.002991   \n",
       "min       0.009000             2.000000              9.000000     0.987110   \n",
       "25%       0.036000            23.000000            108.000000     0.991723   \n",
       "50%       0.043000            34.000000            134.000000     0.993740   \n",
       "75%       0.050000            46.000000            167.000000     0.996100   \n",
       "max       0.346000           289.000000            440.000000     1.038980   \n",
       "\n",
       "                pH    sulphates      alcohol      quality  \n",
       "count  4898.000000  4898.000000  4898.000000  4898.000000  \n",
       "mean      3.188267     0.489847    10.514267     5.877909  \n",
       "std       0.151001     0.114126     1.230621     0.885639  \n",
       "min       2.720000     0.220000     8.000000     3.000000  \n",
       "25%       3.090000     0.410000     9.500000     5.000000  \n",
       "50%       3.180000     0.470000    10.400000     6.000000  \n",
       "75%       3.280000     0.550000    11.400000     6.000000  \n",
       "max       3.820000     1.080000    14.200000     9.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos el fichero CSV con los datos de calidad de los vinos y mostramos algunos datos\n",
    "wine = pd.read_csv('data/winequality-white.csv', sep = ';')\n",
    "wine.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparamos los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Separación de la variable objetivo y las explicativas\n",
    "target = 'quality'\n",
    "features = list(wine.columns)\n",
    "features.remove('quality')\n",
    "\n",
    "x = wine[features]\n",
    "y = wine[target]\n",
    "\n",
    "# Obtencion del conjunto de datos para validación\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos la regresión fordware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paso 1 variable alcohol con RMS 0.796747773237\n",
      "Paso 2 variable volatile acidity con RMS 0.773853659306\n",
      "Paso 3 variable free sulfur dioxide con RMS 0.766448913245\n",
      "Paso 4 variable residual sugar con RMS 0.764090791731\n",
      "Paso 5 variable sulphates con RMS 0.761425077945\n",
      "Paso 6 variable density con RMS 0.757752281888\n",
      "Paso 7 variable pH con RMS 0.755050451517\n",
      "Paso 8 variable fixed acidity con RMS 0.753685601406\n",
      "Paso 9 variable total sulfur dioxide con RMS 0.753580460656\n"
     ]
    }
   ],
   "source": [
    "forward_regression(x, y)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Aplicamos ahorra la regresión backware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En el paso 0 se ha eliminado la varible pH con un error 0.737060995883\n",
      "En el paso 1 se ha eliminado la varible density con un error 0.736788784951\n",
      "En el paso 2 se ha eliminado la varible citric acid con un error 0.736586983635\n",
      "En el paso 3 se ha eliminado la varible chlorides con un error 0.737272579675\n",
      "En el paso 4 se ha eliminado la varible total sulfur dioxide con un error 0.738129330942\n",
      "En el paso 5 se ha eliminado la varible sulphates con un error 0.738894783888\n",
      "En el paso 6 se ha eliminado la varible fixed acidity con un error 0.740568844427\n",
      "En el paso 7 se ha eliminado la varible free sulfur dioxide con un error 0.744269885052\n",
      "En el paso 8 se ha eliminado la varible residual sugar con un error 0.753509212868\n",
      "En el paso 9 se ha eliminado la varible volatile acidity con un error 0.780803673837\n"
     ]
    }
   ],
   "source": [
    "backward_regression(x, y)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 3 Estimación de la supervivencia de los pasajeros del Titanic.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enunciado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando los datos del archivo “titanic.csv”, que contienen información del pasaje del Titanic, para la creación de un modelo que pueda predecir si un pasajero sobrevive al hundimiento del barco en el momento de embarque. Para esto se han de seleccionar la variables con mayor capacidad de predicción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la creación del modelo no se pueden utilizar las variables “boat” ni “body” ya que estas contienen información posterior al momento del embarque."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el conjunto de datos existes valores NaN en las columnas “age” y “fare”, para eliminar las filas con estos valores se puede utilizar el siguiente comando:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    mask = titanic[['age', 'fare']].applymap(lambda x: math.isnan(x))\n",
    "    titanic = titanic[-mask.any(axis = 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Carga de datos del fichero CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los datos se cargan en la variable: titanic\n",
      "La variable titanic es de tipo:  <class 'pandas.core.frame.DataFrame'>\n",
      "La variable titanic tiene 1309 filas (pasajeros).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Anderson, Mr. Harry</td>\n",
       "      <td>male</td>\n",
       "      <td>48.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19952</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>E12</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Andrews, Miss. Kornelia Theodosia</td>\n",
       "      <td>female</td>\n",
       "      <td>63.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13502</td>\n",
       "      <td>77.9583</td>\n",
       "      <td>D7</td>\n",
       "      <td>S</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hudson, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Andrews, Mr. Thomas Jr</td>\n",
       "      <td>male</td>\n",
       "      <td>39.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112050</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>A36</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Belfast, NI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Appleton, Mrs. Edward Dale (Charlotte Lamson)</td>\n",
       "      <td>female</td>\n",
       "      <td>53.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11769</td>\n",
       "      <td>51.4792</td>\n",
       "      <td>C101</td>\n",
       "      <td>S</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bayside, Queens, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Artagaveytia, Mr. Ramon</td>\n",
       "      <td>male</td>\n",
       "      <td>71.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17609</td>\n",
       "      <td>49.5042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Montevideo, Uruguay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived                                             name     sex  \\\n",
       "0       1         1                    Allen, Miss. Elisabeth Walton  female   \n",
       "1       1         1                   Allison, Master. Hudson Trevor    male   \n",
       "2       1         0                     Allison, Miss. Helen Loraine  female   \n",
       "3       1         0             Allison, Mr. Hudson Joshua Creighton    male   \n",
       "4       1         0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
       "5       1         1                              Anderson, Mr. Harry    male   \n",
       "6       1         1                Andrews, Miss. Kornelia Theodosia  female   \n",
       "7       1         0                           Andrews, Mr. Thomas Jr    male   \n",
       "8       1         1    Appleton, Mrs. Edward Dale (Charlotte Lamson)  female   \n",
       "9       1         0                          Artagaveytia, Mr. Ramon    male   \n",
       "\n",
       "     age  sibsp  parch    ticket      fare    cabin embarked boat   body  \\\n",
       "0  29.00      0      0     24160  211.3375       B5        S    2    NaN   \n",
       "1   0.92      1      2    113781  151.5500  C22 C26        S   11    NaN   \n",
       "2   2.00      1      2    113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "3  30.00      1      2    113781  151.5500  C22 C26        S  NaN  135.0   \n",
       "4  25.00      1      2    113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "5  48.00      0      0     19952   26.5500      E12        S    3    NaN   \n",
       "6  63.00      1      0     13502   77.9583       D7        S   10    NaN   \n",
       "7  39.00      0      0    112050    0.0000      A36        S  NaN    NaN   \n",
       "8  53.00      2      0     11769   51.4792     C101        S    D    NaN   \n",
       "9  71.00      0      0  PC 17609   49.5042      NaN        C  NaN   22.0   \n",
       "\n",
       "                         home.dest  \n",
       "0                     St Louis, MO  \n",
       "1  Montreal, PQ / Chesterville, ON  \n",
       "2  Montreal, PQ / Chesterville, ON  \n",
       "3  Montreal, PQ / Chesterville, ON  \n",
       "4  Montreal, PQ / Chesterville, ON  \n",
       "5                     New York, NY  \n",
       "6                       Hudson, NY  \n",
       "7                      Belfast, NI  \n",
       "8              Bayside, Queens, NY  \n",
       "9              Montevideo, Uruguay  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos el fichero CSV con los datos de pasajeros del Titanic y mostramos algunos datos\n",
    "titanic = pd.read_csv(\"data/titanic.csv\", sep=\",\")\n",
    "print 'Los datos se cargan en la variable: titanic'\n",
    "print 'La variable titanic es de tipo: ', type(titanic)\n",
    "print 'La variable titanic tiene', len(titanic), \"filas (pasajeros).\"\n",
    "titanic.head(n = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descripción de variables:\n",
    "- survival : superviviente (0 = No; 1 = Yes)\n",
    "- pclass   : clase de pasajero (1 = 1st; 2 = 2nd; 3 = 3rd)\n",
    "- name     : nombre\n",
    "- sex      : sexo\n",
    "- age      : edad\n",
    "- sibsp    : Número de hermanos / cónyuges bordo\n",
    "- parch    : Númeto de Padres / Niños A bordo\n",
    "- ticket   : número de ticket\n",
    "- fare     : tarifa\n",
    "- cabin    : Cabin\n",
    "- embarked : puerto de embarque (C = Cherbourg; Q = Queenstown; S = Southampton)\n",
    "- boat     : ???\n",
    "- body     : ???\n",
    "- home.dest: destino\n",
    "\n",
    "_Referencia_: [Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1046.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1308.000000</td>\n",
       "      <td>121.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.294882</td>\n",
       "      <td>0.381971</td>\n",
       "      <td>29.881138</td>\n",
       "      <td>0.498854</td>\n",
       "      <td>0.385027</td>\n",
       "      <td>33.295479</td>\n",
       "      <td>160.809917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.837836</td>\n",
       "      <td>0.486055</td>\n",
       "      <td>14.413493</td>\n",
       "      <td>1.041658</td>\n",
       "      <td>0.865560</td>\n",
       "      <td>51.758668</td>\n",
       "      <td>97.696922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "      <td>72.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>155.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.275000</td>\n",
       "      <td>256.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>328.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pclass     survived          age        sibsp        parch  \\\n",
       "count  1309.000000  1309.000000  1046.000000  1309.000000  1309.000000   \n",
       "mean      2.294882     0.381971    29.881138     0.498854     0.385027   \n",
       "std       0.837836     0.486055    14.413493     1.041658     0.865560   \n",
       "min       1.000000     0.000000     0.170000     0.000000     0.000000   \n",
       "25%       2.000000     0.000000    21.000000     0.000000     0.000000   \n",
       "50%       3.000000     0.000000    28.000000     0.000000     0.000000   \n",
       "75%       3.000000     1.000000    39.000000     1.000000     0.000000   \n",
       "max       3.000000     1.000000    80.000000     8.000000     9.000000   \n",
       "\n",
       "              fare        body  \n",
       "count  1308.000000  121.000000  \n",
       "mean     33.295479  160.809917  \n",
       "std      51.758668   97.696922  \n",
       "min       0.000000    1.000000  \n",
       "25%       7.895800   72.000000  \n",
       "50%      14.454200  155.000000  \n",
       "75%      31.275000  256.000000  \n",
       "max     512.329200  328.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable objetivo (target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable objetivo (target) es **survived** que, como veremos a continuación, es una variable binaria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza inicial del conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de empezar con el análisis de variables, aplicaremos la \"limpieza\" de variables y datos sugerida en el enunciado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1º) Eliminamos las columnas 'boat' y 'body', ya que no contienen información relevante para la resolución del problema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Eliminamos las variables del conjunto de datos\n",
    "del titanic['boat']\n",
    "del titanic['body']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2º) Eliminamos las filas que contengan valores NaN en las columnas “age” y “fare”\n",
    "\n",
    "    Podemos hacerlo de varias maneras:\n",
    "\n",
    "        A)  mask = titanic[['age', 'fare']].applymap(lambda x: math.isnan(x))\n",
    "            titanic = titanic[-mask.any(axis = 1)]\n",
    "\n",
    "        B)  titanic = titanic.dropna(how='any', subset=['age', 'fare'])\n",
    "\n",
    "    En esta ocasión lo haremos con la primera de ellas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Guardamos una copia del conjunto de datos original\n",
    "titanic_org = titanic\n",
    "\n",
    "# Eliminamos las filas con valores NaN en age o en fare\n",
    "mask = titanic[['age', 'fare']].applymap(lambda x: math.isnan(x))\n",
    "titanic = titanic[-mask.any(axis = 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nuevo conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número original de filas (pasajeros): 1309\n",
      "Número de filas de datos (pasajeros) descartadas: 264\n",
      "Nuevo número de pasajeros después de eliminar NaN en age y fare: 1045\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived                                             name     sex  \\\n",
       "0       1         1                    Allen, Miss. Elisabeth Walton  female   \n",
       "1       1         1                   Allison, Master. Hudson Trevor    male   \n",
       "2       1         0                     Allison, Miss. Helen Loraine  female   \n",
       "3       1         0             Allison, Mr. Hudson Joshua Creighton    male   \n",
       "4       1         0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
       "\n",
       "     age  sibsp  parch  ticket      fare    cabin embarked  \\\n",
       "0  29.00      0      0   24160  211.3375       B5        S   \n",
       "1   0.92      1      2  113781  151.5500  C22 C26        S   \n",
       "2   2.00      1      2  113781  151.5500  C22 C26        S   \n",
       "3  30.00      1      2  113781  151.5500  C22 C26        S   \n",
       "4  25.00      1      2  113781  151.5500  C22 C26        S   \n",
       "\n",
       "                         home.dest  \n",
       "0                     St Louis, MO  \n",
       "1  Montreal, PQ / Chesterville, ON  \n",
       "2  Montreal, PQ / Chesterville, ON  \n",
       "3  Montreal, PQ / Chesterville, ON  \n",
       "4  Montreal, PQ / Chesterville, ON  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostramos como queda el conjunto de datos\n",
    "print 'Número original de filas (pasajeros):', len(titanic_org)\n",
    "print 'Número de filas de datos (pasajeros) descartadas:', (len(titanic_org) - len(titanic))\n",
    "print 'Nuevo número de pasajeros después de eliminar NaN en age y fare:', len(titanic)\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Discretización de variables y eliminación de variables con poca capacidad predictiva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de crear modelos es conveniente transformar las variables continuas en variables discretas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass          3\n",
       "survived        2\n",
       "name         1043\n",
       "sex             2\n",
       "age            97\n",
       "sibsp           7\n",
       "parch           7\n",
       "ticket        731\n",
       "fare          256\n",
       "cabin         174\n",
       "embarked        3\n",
       "home.dest     348\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtenemos la variabilidad de cada una de las variables\n",
    "titanic.T.apply(lambda x: x.nunique(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>29.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>30.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>25.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived     sex    age  sibsp  parch embarked\n",
       "0       1         1  female  29.00      0      0        S\n",
       "1       1         1    male   0.92      1      2        S\n",
       "2       1         0  female   2.00      1      2        S\n",
       "3       1         0    male  30.00      1      2        S\n",
       "4       1         0  female  25.00      1      2        S"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eliminamos las variables que muestran mayor variabilidad y aportan poca capacidad predictiva, \n",
    "# como los id's, pseudo-id's, variables con excesiva variabilidad...: \n",
    "# name, ticket, cabin, fate y home.dest\n",
    "del titanic['name']\n",
    "del titanic['ticket']\n",
    "del titanic['fare']\n",
    "del titanic['cabin']\n",
    "del titanic['home.dest']\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores de la variable survived:  [1 0]\n",
      "Valores de la variable pclass..:  [1 2 3]\n",
      "Valores de la variable sex.....:  ['female' 'male']\n",
      "Valores de la variable sibsp...:  [0 1 2 3 4 5 8]\n",
      "Valores de la variable parch...:  [0 2 1 4 3 5 6]\n",
      "Valores de la variable embarked:  ['S' 'C' nan 'Q']\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos los valores distintos de la variable objetivo\n",
    "print 'Valores de la variable survived: ', titanic.survived.unique()\n",
    "\n",
    "# Obtenemos los valores distintos de las variables que muestran menor variabilidad\n",
    "print 'Valores de la variable pclass..: ', titanic.pclass.unique()\n",
    "print 'Valores de la variable sex.....: ', titanic.sex.unique()\n",
    "print 'Valores de la variable sibsp...: ', titanic.sibsp.unique()\n",
    "print 'Valores de la variable parch...: ', titanic.parch.unique()\n",
    "print 'Valores de la variable embarked: ', titanic.embarked.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Clasificamos las variables segun sus características\n",
    "var_target = titanic['survived']\n",
    "var_numericas = ['age']\n",
    "var_categoricas = ['pclass', 'sex', 'sibsp', 'parch', 'embarked']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Análisis de las  variables categóricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las variables se pueden analizar utilizando tablas de frecuencia para comprobar la forma en que se reparten sus valores.\n",
    "\n",
    "En las variables con niveles con pocos registros significativos hay que hacer reagrupaciones de éstos últimos con otros, de forma que puedan ser significativos. Para ello se puede utilizar el peso de la evidencia (WoE, Weight of Evidence), comparando la capacidad predictiva de cada uno de los niveles de la variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Tabla de frecuencias para la variable pclass respecto de la variable survived:\n",
      "pclass      1    2    3\n",
      "survived               \n",
      "0         103  146  369\n",
      "1         181  115  131\n",
      "\n",
      "*** Tabla de frecuencias para la variable sex respecto de la variable survived:\n",
      "sex       female  male\n",
      "survived              \n",
      "0             96   522\n",
      "1            292   135\n",
      "\n",
      "*** Tabla de frecuencias para la variable sibsp respecto de la variable survived:\n",
      "sibsp       0    1   2   3   4  5  8\n",
      "survived                            \n",
      "0         429  133  20  10  19  6  1\n",
      "1         255  147  16   6   3  0  0\n",
      "\n",
      "*** Tabla de frecuencias para la variable parch respecto de la variable survived:\n",
      "parch       0   1   2  3  4  5  6\n",
      "survived                         \n",
      "0         497  65  42  3  4  5  2\n",
      "1         270  95  55  5  1  1  0\n",
      "\n",
      "*** Tabla de frecuencias para la variable embarked respecto de la variable survived:\n",
      "embarked    C   Q    S\n",
      "survived              \n",
      "0          80  37  501\n",
      "1         132  13  280\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos las tablas de frecuencias de las variables categóricas respecto de la variable survived\n",
    "for var in var_categoricas:\n",
    "    print \"*** Tabla de frecuencias para la variable\", var, \"respecto de la variable survived:\"\n",
    "    print pd.crosstab(titanic['survived'], titanic[var])\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las variables sibsp y parch presentan niveles con pocos registros, por lo que las reagruparemos utilizando el peso de la evidencia (WoE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creamos una función para determinar el peso de la evidencia de los niveles de una variable\n",
    "def get_WoE(data, var, target):\n",
    "    crosstab = pd.crosstab(data[target], data[var])\n",
    "    print \"Obteniendo el Woe para la variable\", var, \":\"    \n",
    "    for col in crosstab.columns:\n",
    "        if crosstab[col][1] == 0:\n",
    "            print \"  El WoE para\", col, \"[\", sum(crosstab[col]), \"] es infinito\"\n",
    "        else:\n",
    "            print \"  El WoE para\", col, \"[\", sum(crosstab[col]), \"] es\", np.log(float(crosstab[col][0]) / float(crosstab[col][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reagrupamos la variable sibsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obteniendo el Woe para la variable sibsp :\n",
      "  El WoE para 0 [ 684 ] es 0.52019337377\n",
      "  El WoE para 1 [ 280 ] es -0.100083458557\n",
      "  El WoE para 2 [ 36 ] es 0.223143551314\n",
      "  El WoE para 3 [ 16 ] es 0.510825623766\n",
      "  El WoE para 4 [ 22 ] es 1.8458266905\n",
      "  El WoE para 5 [ 6 ] es infinito\n",
      "  El WoE para 8 [ 1 ] es infinito\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos el peso de la evidencia de la variable\n",
    "get_WoE(titanic, 'sibsp', 'survived') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable sibsp presenta muy pocas ocurrencias de los valores 2, 3, 4, 5 y 8 en comparación con los valores 0 y 1.\n",
    "Por ello vamos a reagrupar los valores y crear una nueva clasificación sibspX: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obteniendo el Woe para la variable sibspX :\n",
      "  El WoE para n0 [ 700 ] es 0.519979005752\n",
      "  El WoE para n1 [ 280 ] es -0.100083458557\n",
      "  El WoE para n2 [ 36 ] es 0.223143551314\n",
      "  El WoE para n9 [ 29 ] es 2.15948424935\n"
     ]
    }
   ],
   "source": [
    "# Reagrupamos los valores de la variable en nuevos niveles\n",
    "titanic.loc[:, 'sibspX'] = None\n",
    "\n",
    "for row in titanic.index:\n",
    "    if   titanic.loc[row, 'sibsp'] in (0, 3):\n",
    "        titanic.loc[row, 'sibspX'] = 'n0'\n",
    "    elif titanic.loc[row, 'sibsp'] == 1:\n",
    "        titanic.loc[row, 'sibspX'] = 'n1'\n",
    "    elif titanic.loc[row, 'sibsp'] == 2:\n",
    "        titanic.loc[row, 'sibspX'] = 'n2'\n",
    "    else:\n",
    "        titanic.loc[row, 'sibspX'] = 'n9'\n",
    "\n",
    "get_WoE(titanic, 'sibspX', 'survived') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reagrupamos la variable parch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obteniendo el Woe para la variable parch :\n",
      "  El WoE para 0 [ 767 ] es 0.610168067098\n",
      "  El WoE para 1 [ 160 ] es -0.379489621705\n",
      "  El WoE para 2 [ 97 ] es -0.269663566949\n",
      "  El WoE para 3 [ 8 ] es -0.510825623766\n",
      "  El WoE para 4 [ 5 ] es 1.38629436112\n",
      "  El WoE para 5 [ 6 ] es 1.60943791243\n",
      "  El WoE para 6 [ 2 ] es infinito\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos el peso de la evidencia de la variable\n",
    "get_WoE(titanic, 'parch', 'survived') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable parch presenta muy pocas ocurrencias de los valores 3, 4, 5 y 6 en comparación con los valores 0, 1 y 2.\n",
    "Por ello vamos a reagrupar los valores y crear una nueva clasificación parchX: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obteniendo el Woe para la variable parchX :\n",
      "  El WoE para n0 [ 767 ] es 0.610168067098\n",
      "  El WoE para n1 [ 168 ] es -0.385662480812\n",
      "  El WoE para n2 [ 97 ] es -0.269663566949\n",
      "  El WoE para n9 [ 13 ] es 1.70474809224\n"
     ]
    }
   ],
   "source": [
    "# Reagrupamos los valores de la variable en nuevos niveles\n",
    "titanic.loc[:, 'parchX'] = None\n",
    "\n",
    "for row in titanic.index:\n",
    "    if   titanic.loc[row, 'parch'] == 0:\n",
    "        titanic.loc[row, 'parchX'] = 'n0'\n",
    "    elif titanic.loc[row, 'parch'] in (1, 3):\n",
    "        titanic.loc[row, 'parchX'] = 'n1'\n",
    "    elif titanic.loc[row, 'parch'] == 2:\n",
    "        titanic.loc[row, 'parchX'] = 'n2'\n",
    "    else:\n",
    "        titanic.loc[row, 'parchX'] = 'n9'\n",
    "\n",
    "get_WoE(titanic, 'parchX', 'survived') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Análisis de las variables continuas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las variables continuas pueden analizarse mediante la utilización de histogramas.\n",
    "Se obtienen histogramas tanto para los valores positivos de la variable target (objetivo) como para los valores negativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7fb63007ac90>]], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEKCAYAAAAcgp5RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb63007ab10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histogramas de variables continuas para valores positivos del target\n",
    "titanic[var_numericas][var_target == 1].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7fb62bf52e10>]], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEKCAYAAAAcgp5RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb62bf9b9d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histogramas de variables continuas para valores negativos del target\n",
    "titanic[var_numericas][var_target == 0].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable age\n",
    "\n",
    "Vamos a analizar la varaible age superponiendo sus histogramas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEKCAYAAAAcgp5RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIhGnRC8iEnFK9CIiEff/AQsLbjwd+mQuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb62ba76710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(titanic['age'][var_target == 1], bins=10, histtype='bar', color='blue', label='age (survived=1)') \n",
    "plt.hist(titanic['age'][var_target == 0], bins=10, histtype='bar', color='cyan', label='age (survived=0)', alpha=0.5)\n",
    "plt.title('Histograma: age')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver varias zonas, pero seleccionaremos las siguientes para hacer una nueva agrupación binaria:\n",
    "- survived = 1:\n",
    "    - age < 15\n",
    "    - age >= 52 and age <=57\n",
    "    - age > 75\n",
    "- survived = 0\n",
    "    - el resto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obteniendo el Woe para la variable ageX :\n",
      "  El WoE para n0 [ 896 ] es 0.463479503169\n",
      "  El WoE para n1 [ 149 ] es -0.174941449496\n"
     ]
    }
   ],
   "source": [
    "titanic.loc[:, 'ageX'] = titanic['age'].map(lambda x: 'n1' if x<15 or (x>=52 and x<=57) or x>75 else 'n0')\n",
    "get_WoE(titanic, 'ageX', 'survived') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Nuevo conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Eliminamos las variables reemplazadas\n",
    "del titanic['age']\n",
    "del titanic['sibsp']\n",
    "del titanic['parch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>embarked</th>\n",
       "      <th>sibspX</th>\n",
       "      <th>parchX</th>\n",
       "      <th>ageX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>n0</td>\n",
       "      <td>n0</td>\n",
       "      <td>n0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>n1</td>\n",
       "      <td>n2</td>\n",
       "      <td>n1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>n1</td>\n",
       "      <td>n2</td>\n",
       "      <td>n1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>n1</td>\n",
       "      <td>n2</td>\n",
       "      <td>n0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>n1</td>\n",
       "      <td>n2</td>\n",
       "      <td>n0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived     sex embarked sibspX parchX ageX\n",
       "0       1         1  female        S     n0     n0   n0\n",
       "1       1         1    male        S     n1     n2   n1\n",
       "2       1         0  female        S     n1     n2   n1\n",
       "3       1         0    male        S     n1     n2   n0\n",
       "4       1         0  female        S     n1     n2   n0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostramos el nuevo conjunto de datos\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Actualizamos la lista de variables\n",
    "var_target = titanic['survived']\n",
    "var_numericas = []\n",
    "var_categoricas = ['pclass', 'sex', 'embarked', 'sibspX', 'parchX', 'ageX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Tabla de frecuencias para la variable pclass respecto de la variable survived:\n",
      "pclass      1    2    3\n",
      "survived               \n",
      "0         103  146  369\n",
      "1         181  115  131\n",
      "*** Tabla de frecuencias para la variable sex respecto de la variable survived:\n",
      "sex       female  male\n",
      "survived              \n",
      "0             96   522\n",
      "1            292   135\n",
      "*** Tabla de frecuencias para la variable embarked respecto de la variable survived:\n",
      "embarked    C   Q    S\n",
      "survived              \n",
      "0          80  37  501\n",
      "1         132  13  280\n",
      "*** Tabla de frecuencias para la variable sibspX respecto de la variable survived:\n",
      "sibspX     n0   n1  n2  n9\n",
      "survived                  \n",
      "0         439  133  20  26\n",
      "1         261  147  16   3\n",
      "*** Tabla de frecuencias para la variable parchX respecto de la variable survived:\n",
      "parchX     n0   n1  n2  n9\n",
      "survived                  \n",
      "0         497   68  42  11\n",
      "1         270  100  55   2\n",
      "*** Tabla de frecuencias para la variable ageX respecto de la variable survived:\n",
      "ageX       n0  n1\n",
      "survived         \n",
      "0         550  68\n",
      "1         346  81\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos las tablas de frecuencias de las variables categóricas respecto de la variable objetivo (survived)\n",
    "for var in var_categoricas:\n",
    "    print \"*** Tabla de frecuencias para la variable\", var, \"respecto de la variable survived:\"\n",
    "    print pd.crosstab(titanic['survived'], titanic[var])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Eliminación recursiva de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Valor informativo (IV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez discretizadas las variables, vamos a analizar la capacidad de clasificacion de cada una de ellas mediante el algoritmo \"Informative Value\", para ver cuales vamos a dejar en el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "\n",
    "# Creamos una función para mostrar IV de un conjunto de datos\n",
    "def calculateIV(datos, variables, target):\n",
    "\n",
    "    # Iniciamos la variable resultado\n",
    "    result_IV = []\n",
    "\n",
    "    # Realizamos el cálculo para cada variable\n",
    "    for v_cat in variables:\n",
    "        var_target = array(target)\n",
    "        var_values = array(datos[v_cat])\n",
    "        var_levels = unique(var_values)\n",
    "\n",
    "        mat_values = numpy.zeros(shape=(len(var_levels),2))\n",
    "\n",
    "        for i in range(len(var_target)):\n",
    "            # Obtenemos la posición en los niveles del valor\n",
    "            for j in range(len(var_levels)):\n",
    "                if var_levels[j] == var_values[i]:\n",
    "                    pos = j\n",
    "                    break\n",
    "\n",
    "            # Estimamos el número de valores en cada nivel\n",
    "            if var_target[i]:\n",
    "                mat_values[pos][0] += 1\n",
    "            else:\n",
    "                mat_values[pos][1] += 1\n",
    "\n",
    "            # Obtenemos el IV\n",
    "            IV = 0\n",
    "            for j in range(len(var_levels)):\n",
    "                if mat_values[j][0] > 0 and mat_values[j][1] > 0:\n",
    "                    rt = mat_values[j][0] / (mat_values[j][0] + mat_values[j][1])\n",
    "                    rf = mat_values[j][1] / (mat_values[j][0] + mat_values[j][1])\n",
    "                    IV += (rt - rf) * np.log(rt / rf)\n",
    "\n",
    "        # Agregamos el IV al listado\n",
    "        result_IV.append(IV)\n",
    "\n",
    "    # Mostramos los resultados\n",
    "    for i in range(len(var_categoricas)):\n",
    "        print \"La variable\", var_categoricas[i], \"el IV es\", result_IV[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La variable pclass el IV es 0.67613129015\n",
      "La variable sex el IV es 1.35855179749\n",
      "La variable embarked el IV es 0.791228338157\n",
      "La variable sibspX el IV es 1.8747155384\n",
      "La variable parchX el IV es 1.47039450695\n",
      "La variable ageX el IV es 0.120787699111\n"
     ]
    }
   ],
   "source": [
    "calculateIV(titanic, var_categoricas, var_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las variables que tienen poder de clasificacion fuerte tienen un valor por encima de 0.3\n",
    "Las variables que tienen poder de clasificacion muy fuerte tienen un valor por encima de 0.5\n",
    "En este caso vamos a escoger: pclass, sex, embarked, sibspX y parchX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Eliminamos las variables deshechadas\n",
    "del titanic['ageX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>embarked</th>\n",
       "      <th>sibspX</th>\n",
       "      <th>parchX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>n0</td>\n",
       "      <td>n0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>n1</td>\n",
       "      <td>n2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>n1</td>\n",
       "      <td>n2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>n1</td>\n",
       "      <td>n2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>n1</td>\n",
       "      <td>n2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived     sex embarked sibspX parchX\n",
       "0       1         1  female        S     n0     n0\n",
       "1       1         1    male        S     n1     n2\n",
       "2       1         0  female        S     n1     n2\n",
       "3       1         0    male        S     n1     n2\n",
       "4       1         0  female        S     n1     n2"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostramos el nuevo conjunto de datos\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Actualizamos la lista de variables categoricas\n",
    "var_categoricas = ['pclass', 'sex', 'embarked', 'sibspX', 'parchX']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a ver qué aportan las variables para la predicción del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** pclass\n",
      "Precisión: 66.6 %\n",
      "Exactitud: 42.39 %\n",
      "Exhaustividad: 63.73 %\n",
      "** sex\n",
      "Precisión: 77.89 %\n",
      "Exactitud: 68.38 %\n",
      "Exhaustividad: 75.26 %\n",
      "** embarked\n",
      "Precisión: 64.11 %\n",
      "Exactitud: 30.91 %\n",
      "Exhaustividad: 62.26 %\n",
      "** sibspX\n",
      "Precisión: 60.48 %\n",
      "Exactitud: 34.43 %\n",
      "Exhaustividad: 52.5 %\n",
      "** parchX\n",
      "Precisión: 63.44 %\n",
      "Exactitud: 36.3 %\n",
      "Exhaustividad: 58.49 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, auc, confusion_matrix, f1_score, precision_score, recall_score, roc_curve\n",
    "\n",
    "for v_cat in var_categoricas:\n",
    "    dum_var    = pd.get_dummies(titanic[v_cat])\n",
    "    features   = list(dum_var.columns)\n",
    "    features.remove(features[1])\n",
    "    classifier = LogisticRegression().fit(dum_var, var_target)\n",
    "    y_pred     = classifier.predict(dum_var)\n",
    "    \n",
    "    print \"**\", v_cat\n",
    "    print 'Precisión:', round(100 * accuracy_score(y_pred, var_target), 2), '%'\n",
    "    print 'Exactitud:', round(100 * precision_score(y_pred, var_target), 2), '%'\n",
    "    print 'Exhaustividad:', round(100 * recall_score(y_pred, var_target), 2), '%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas las variables presentan una precision (porcentaje de aciertos en positivos y negativos) por encima del 50%, por lo que todas ellas son buenas para nuestro modelo. Las variables sex y pclass son las que tienen mayor precisión, las mejores para predecir el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic_org = titanic.copy(deep = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass_2</th>\n",
       "      <th>pclass_3</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "      <th>sibspX_n1</th>\n",
       "      <th>sibspX_n2</th>\n",
       "      <th>sibspX_n9</th>\n",
       "      <th>parchX_n1</th>\n",
       "      <th>parchX_n2</th>\n",
       "      <th>parchX_n9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1045.000000</td>\n",
       "      <td>1045.000000</td>\n",
       "      <td>1045.000000</td>\n",
       "      <td>1045.000000</td>\n",
       "      <td>1045.000000</td>\n",
       "      <td>1045.000000</td>\n",
       "      <td>1045.000000</td>\n",
       "      <td>1045.000000</td>\n",
       "      <td>1045.000000</td>\n",
       "      <td>1045.000000</td>\n",
       "      <td>1045.000000</td>\n",
       "      <td>1045.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.408612</td>\n",
       "      <td>0.249761</td>\n",
       "      <td>0.478469</td>\n",
       "      <td>0.628708</td>\n",
       "      <td>0.047847</td>\n",
       "      <td>0.747368</td>\n",
       "      <td>0.267943</td>\n",
       "      <td>0.034450</td>\n",
       "      <td>0.027751</td>\n",
       "      <td>0.160766</td>\n",
       "      <td>0.092823</td>\n",
       "      <td>0.012440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.491813</td>\n",
       "      <td>0.433082</td>\n",
       "      <td>0.499775</td>\n",
       "      <td>0.483382</td>\n",
       "      <td>0.213544</td>\n",
       "      <td>0.434729</td>\n",
       "      <td>0.443100</td>\n",
       "      <td>0.182469</td>\n",
       "      <td>0.164338</td>\n",
       "      <td>0.367490</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.110893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          survived     pclass_2     pclass_3     sex_male   embarked_Q  \\\n",
       "count  1045.000000  1045.000000  1045.000000  1045.000000  1045.000000   \n",
       "mean      0.408612     0.249761     0.478469     0.628708     0.047847   \n",
       "std       0.491813     0.433082     0.499775     0.483382     0.213544   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     1.000000     0.000000   \n",
       "75%       1.000000     0.000000     1.000000     1.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        embarked_S    sibspX_n1    sibspX_n2    sibspX_n9    parchX_n1  \\\n",
       "count  1045.000000  1045.000000  1045.000000  1045.000000  1045.000000   \n",
       "mean      0.747368     0.267943     0.034450     0.027751     0.160766   \n",
       "std       0.434729     0.443100     0.182469     0.164338     0.367490   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       1.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       1.000000     1.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "         parchX_n2    parchX_n9  \n",
       "count  1045.000000  1045.000000  \n",
       "mean      0.092823     0.012440  \n",
       "std       0.290323     0.110893  \n",
       "min       0.000000     0.000000  \n",
       "25%       0.000000     0.000000  \n",
       "50%       0.000000     0.000000  \n",
       "75%       0.000000     0.000000  \n",
       "max       1.000000     1.000000  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for column in var_categoricas:\n",
    "    dummie = pd.get_dummies(titanic[column], prefix = column)\n",
    "    names = list(dummie.columns)\n",
    "    names.remove(names[0])\n",
    "    titanic = pd.concat([titanic, dummie[names]], axis = 1)\n",
    "    names = list(titanic.columns)\n",
    "    names.remove(column)\n",
    "    titanic = titanic[names]\n",
    "    \n",
    "titanic.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Actualizamos la nueva lista de variables para el modelo\n",
    "var_categoricas = ['pclass_2', 'pclass_3', 'sex_male', 'embarked_Q', 'embarked_S', 'sibspX_n1', 'sibspX_n2', 'sibspX_n9', 'parchX_n1', 'parchX_n2', 'parchX_n9']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factor de inflación de la varianza (VIF), colinealidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a ver la colinealidad de las variables. Si alguna es colineal podemos quitarla del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a calcular el valor del VIF para todas las variables menos la objetivo. Realizaremos una regresión lineal de cada una de las variables frente al resto y aplicamos la fórmula del VIF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def calculateVIF(data):\n",
    "    features = list(data.columns)\n",
    "    num_features = len(features)\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    \n",
    "    result = pd.DataFrame(index = ['VIF'], columns = features)\n",
    "    result = result.fillna(0)\n",
    "    \n",
    "    for ite in range(num_features):\n",
    "        x_features = features[:]\n",
    "        y_featue = features[ite]\n",
    "        x_features.remove(y_featue)\n",
    "        \n",
    "        x = data[x_features]\n",
    "        y = data[y_featue]\n",
    "        \n",
    "        model.fit(data[x_features], data[y_featue])\n",
    "        \n",
    "        result[y_featue] = 1/(1 - model.score(data[x_features], data[y_featue]))\n",
    "    \n",
    "    return result\n",
    "\n",
    "def selectDataUsingVIF(data, max_VIF = 5):\n",
    "    result = data.copy(deep = True)\n",
    "    \n",
    "    VIF = calculateVIF(result)\n",
    "    \n",
    "    while VIF.as_matrix().max() > max_VIF:\n",
    "        col_max = np.where(VIF == VIF.as_matrix().max())[1][0]\n",
    "        features = list(result.columns)\n",
    "        features.remove(features[col_max])\n",
    "        result = result[features]\n",
    "        \n",
    "        VIF = calculateVIF(result)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de variables: 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass_2</th>\n",
       "      <th>pclass_3</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "      <th>sibspX_n1</th>\n",
       "      <th>sibspX_n2</th>\n",
       "      <th>sibspX_n9</th>\n",
       "      <th>parchX_n1</th>\n",
       "      <th>parchX_n2</th>\n",
       "      <th>parchX_n9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VIF</th>\n",
       "      <td>1.629665</td>\n",
       "      <td>1.744888</td>\n",
       "      <td>1.115465</td>\n",
       "      <td>1.304368</td>\n",
       "      <td>1.39721</td>\n",
       "      <td>1.202039</td>\n",
       "      <td>1.036359</td>\n",
       "      <td>1.235872</td>\n",
       "      <td>1.191852</td>\n",
       "      <td>1.244306</td>\n",
       "      <td>1.04746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pclass_2  pclass_3  sex_male  embarked_Q  embarked_S  sibspX_n1  \\\n",
       "VIF  1.629665  1.744888  1.115465    1.304368     1.39721   1.202039   \n",
       "\n",
       "     sibspX_n2  sibspX_n9  parchX_n1  parchX_n2  parchX_n9  \n",
       "VIF   1.036359   1.235872   1.191852   1.244306    1.04746  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print 'Número de variables:', len(var_categoricas)\n",
    "calculateVIF(titanic[var_categoricas])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas las variables presentan valores por debajo de 5, por lo que no hay que eliminar ninguna variable del modelo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Creación de muestras de entrenamiento y validación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la evaluación de modelos predictivos se utilizan técnicas de separación de los datos en un conjunto de entrenamiento (train) y un conjunto de prueba (test). Los modelos se entrenan con los datos del conjunto de entrenamiento (train) y se evalúan con los datos del conjunto de prueba (test).\n",
    "\n",
    "Scikit learn contiene una función que permite separar los datos de entrenamiento de los de prueba, automáticamente y de forma aleatoria. El método se llama cross_validation.train_test_split, y permite indicar el porcentaje de muestras que queramos para cada conjunto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1045, 12) xtrain: (836, 11) xtest (209, 11)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Obtenemos las muestras de entrenamiento (80%) y prueba (20%)\n",
    "x = titanic[var_categoricas]\n",
    "y = titanic['survived']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "print titanic.shape,\"xtrain:\",  x_train.shape, \"xtest\", x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos cuatro conjuntos, dos versiones de los datos de las dimensiones que generalmente llamamos features y dos versiones de las clases. Una versión es para entrenar (train) y otra para probar (test). Hemos asignado el 80% de los datos a la versión de entrenamiento, y el 20% restante a la versión de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Análisis de variables del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora debemos seleccionar, de entre todas las variables candidatas a ser explicativas de la variable dependiente, un subconjunto que resulte suficientemente explicativo. Para ello se suelen utilizar métodos más o menos automáticos, como el método **logistic_regression** que impementamos a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic_regression(x, y):\n",
    "    # Obtencion del conjunto de datos para validación\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "\n",
    "    # Modelo para realizar los ajustes\n",
    "    model = LogisticRegression()\n",
    "\n",
    "    # Variable para almacenar los índices de la lista de atributos usados\n",
    "    feature_list = list(x.columns)\n",
    "    feature_order = []\n",
    "    feature_error = []\n",
    "    feature_names = []\n",
    "\n",
    "    # Iteración sobre todas las variables\n",
    "    for i in range(len(feature_list)):\n",
    "        idx_try = [val for val in range(len(feature_list)) if val not in feature_order]\n",
    "        iter_error = []\n",
    "\n",
    "        for i_try in idx_try:\n",
    "            useRow = feature_order[:]\n",
    "            useRow.append(i_try)\n",
    "\n",
    "            use_train = x_train[x_train.columns[useRow]]\n",
    "            use_test = x_test[x_train.columns[useRow]]\n",
    "\n",
    "            model.fit(use_train, y_train)\n",
    "            rmsError = numpy.linalg.norm((y_test - model.predict(use_test)), 2)/sqrt(len(y_test))\n",
    "            iter_error.append(rmsError)\n",
    "\n",
    "        # Guardamos la posicion de la combinacion con el menor error\n",
    "        pos_best = numpy.argmin(iter_error)\n",
    "        \n",
    "        if len(feature_error) == 0 or (iter_error[pos_best] < feature_error[-1]):\n",
    "            feature_order.append(idx_try[pos_best])\n",
    "            feature_error.append(iter_error[pos_best])\n",
    "            feature_names.append(feature_list[idx_try[pos_best]])\n",
    "            print \"Paso\", len(feature_error), \"variable\", feature_list[idx_try[pos_best]], \"con RMS\", iter_error[pos_best]\n",
    "        else:\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paso 1 variable sex_male con RMS 0.436852028331\n",
      "Paso 2 variable sibspX_n9 con RMS 0.432461444251\n",
      "Paso 3 variable parchX_n9 con RMS 0.428025825004\n"
     ]
    }
   ],
   "source": [
    "# Aplicamos el método logistic_regression\n",
    "logistic_regression(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Actualizamos la nueva lista de variables para el modelo\n",
    "var_categoricas = [ 'sex_male', 'sibspX_n9', 'parchX_n9' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.8 Evaluación del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sobreajuste**\n",
    "\n",
    "Para evaluar la calidad de un modelo es importante medir el error en el conjunto de entrenamiento y en la predicción.\n",
    "\n",
    "La utilización exclusiva del error del conjunto de entrenamiento puede conducir a resultados engañosos.\n",
    "\n",
    "Estos errores pueden conducir a un fenómeno de sobreajuste (overfitting), en el cual el modelo se ajusta muy bien a los datos exitentes pero tiene un pobre rendimiento para predecir nuevos resultados.\n",
    "\n",
    "**Curvas ROC**\n",
    "\n",
    "Para evaluar la capacidad predictiva de los modelos de regresión ajustados empleamos las curvas ROC. Mediante el análisis ROC podemos elegir un subconjunto de clasificadores entre los cuales seguro estará el clasificador óptimo para cualquier contexto posible.\n",
    "\n",
    "El modelo de regresión constituye un clasificador probabilístico, ya que nos proporciona las probabilidades de pertenencia a la clase I (Y=1, casos). Empleamos como indicador el AUC.\n",
    "\n",
    "El clasificador probabilístico será mejor cuanto mayor sea área bajo la curva ROC (AUC, Area Under the ROC Curve).\n",
    "\n",
    "Las AUC para los conjuntos de entrenamiento y prueba no deberían diferir más del 20% entre sí.\n",
    "\n",
    "**Matriz de confusión**\n",
    "\n",
    "La matriz de confusión es una herramienta que permite la visualización del desempeño de un algoritmo de aprendizaje supervisado. Cada columna de la matriz representa el número de predicciones de cada clase, mientras que cada fila representa a las instancias en la clase real. Uno de los beneficios de las matrices de confusión es que facilitan ver si el sistema está confundiendo dos clases.\n",
    "\n",
    "**Clasificación**\n",
    "\n",
    "En scikit-learn hay tres métodos básicos para clasificación dado un modelo:\n",
    "- **modelo.fit(X, y)**: ajuste de los parámetros del modelo a los datos\n",
    "- **modelo.predict(X)**: predicción de los valores de salida para datos nuevos\n",
    "- **modelo.score(X, y)**: método de evaluación de la predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, auc, confusion_matrix, f1_score, precision_score, recall_score, roc_curve\n",
    "\n",
    "# Creamos una función para el cálculo de métricas de cada variable\n",
    "def metricas_modelos(y_true, y_pred):\n",
    "    from sklearn.metrics import accuracy_score, auc, confusion_matrix, f1_score, precision_score, recall_score, roc_curve\n",
    "\n",
    "    # Obtención de matriz de confusión\n",
    "    confusion_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    print \"La matriz de confusión es \"\n",
    "    print confusion_matrix\n",
    "\n",
    "    print 'Precisión:', accuracy_score(y_true, y_pred)\n",
    "    print 'Exactitud:', precision_score(y_true, y_pred) \n",
    "    print 'Exhaustividad:', recall_score(y_true, y_pred)\n",
    "    print 'F1:', f1_score(y_true, y_pred)\n",
    "\n",
    "    false_positive_rate, recall, thresholds = roc_curve(y_true, y_pred)\n",
    "    roc_auc = auc(false_positive_rate, recall)\n",
    "\n",
    "    print 'AUC:', auc(false_positive_rate, recall)\n",
    "\n",
    "    plot(false_positive_rate, recall, 'b')\n",
    "    plot([0, 1], [0, 1], 'r--')\n",
    "    title('AUC = %0.2f' % roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Obtenemos las muestras de entrenamiento y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1045, 12) xtrain: (836, 3) xtest (209, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Obtenemos las muestras de entrenamiento (80%) y prueba (20%)\n",
    "x = titanic[var_categoricas]\n",
    "y = titanic['survived']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "print titanic.shape,\"xtrain:\",  x_train.shape, \"xtest\", x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Importamos el modelo\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "\n",
    "# Creamos el modelo\n",
    "rlog = LogisticRegression() \n",
    "\n",
    "# Ajustamos el modelo (Obtenemos la clasificación)\n",
    "classifier = rlog.fit(x_train, y_train) \n",
    "\n",
    "# Realizamos las predicciones\n",
    "y_predic_train = classifier.predict(x_train) \n",
    "y_predic_test = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sobre datos de entrenamiento: 0.78\n",
      "sobre datos de evaluación: 0.83\n"
     ]
    }
   ],
   "source": [
    "# Verificamos la exactitud del modelo\n",
    "train = (y_predic_train == y_train).sum().astype(float) / y_train.shape[0]\n",
    "print(\"sobre datos de entrenamiento: {0:.2f}\".format(train))\n",
    "test = (y_predic_test == y_test).sum().astype(float) / y_test.shape[0]\n",
    "print(\"sobre datos de evaluación: {0:.2f}\".format(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, nuestro modelo tiene bastante precisión clasificando las categorías de nuestro dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La matriz de confusión es \n",
      "[[423  71]\n",
      " [116 226]]\n",
      "Precisión: 0.776315789474\n",
      "Exactitud: 0.760942760943\n",
      "Exhaustividad: 0.66081871345\n",
      "F1: 0.707355242567\n",
      "AUC: 0.758547008547\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEKCAYAAAD3tSVSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb62b97f850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Obtenemos la matriz de confusión para el conjunto de datos de entrenamiento\n",
    "metricas_modelos(y_train, y_predic_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La matriz de confusión es \n",
      "[[112  12]\n",
      " [ 23  62]]\n",
      "Precisión: 0.832535885167\n",
      "Exactitud: 0.837837837838\n",
      "Exhaustividad: 0.729411764706\n",
      "F1: 0.779874213836\n",
      "AUC: 0.816318785579\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEKCAYAAAD3tSVSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHyRJREFUeJzt3XuQVeWZ7/Hvw00xAiPeoiAoNxERvKBxSk/Zo+eMOHNG\n5xiN4niPU4yXaGoyR2OqUqAzGcczdWocx4kpJkbjJSIVo3I0mdEYOnPMUbRBVATkonKnd2iQO9I0\nz/lj7Q2L3d306t17r9v+fap20bt77b1fl/Dj5Xmf9S5zd0REJJ96JT0AERGpHYW8iEiOKeRFRHJM\nIS8ikmMKeRGRHFPIi4jkmEJeRCTHFPKSGmbWaGabzKxv2ffnmNmtZd+7yMxWl33vbjP7yMy2m9kq\nM3vBzE6v8hiPMrOXip/xmZlN6eL4vzOzNWa22cx+Y2bjit/vZ2Y/NrPPzWyLmc03s8nVHKsIKOQl\nJcxsOHAhsA+4POLL9l/JZ2aPAt8C7gKOAsYALwN/Wt2R8kNgN3AscD3wuJmd1tGBZvYN4GbgAmAw\n8A7wTPHHfYBVwH9x90HA94FZZjasyuOVOtcn6QGIFN0IvA3MJQjGF6O+0MxGA3cAX3P3ecVvtwLP\nV3OAZnYEcCUwzt13Ab8zs1eAG4DvdfCSk4G33H1l8fXPAt8GcPedwIOlA939NTP7DDiHIPxFqkIz\neUmLG4FngZ8Bl5rZsd147SXA6lDAd8nM/rVYQtkU+rX09YJOXjYGaHX3FaHvfQB0VhKaCYw0s9HF\nEtTNwK86Gc/xwGjg46j/DSJRaCYviTOzC4FhwCx332xmy4HrgH+O+BaDgfXd+Ux3vxO4s1sDhSOB\nrWXf2woM6OT49cDvgE+AvcBq4OLyg8ysD8FfcE+5+9JujknkkDSTlzS4EXjd3TcXnz8P3BT6+V6g\nb9lr+hKUZABagBNqOsLAdmBg2fcGAds6OX4acC4wBDicoDwzx8wOLx1gZkYQ8F8SrCmIVJVCXhJV\nDLxvABeZ2XozW09Qt55oZmcUD1tFUN8OGwGsLH79JjDUzM7uxuc+bmbbzGxr2WObmX3UycuWAn3M\nbGToexPpvMQyEZjp7uvdfZ+7/5RgUXhc6JgngGOAK929Ler4RaJSyEvS/gfBTP00glCcWPz6/xLM\n8AFeAG4xs3MBzGwMwV8EzwO4+3KCrpfni62Vfc3sMDO7xszu7ehD3f12dx/g7gPLHgPc/YxOXrMT\n+AXwoJkdUSwz/RkHOmbKvQdcbWbHWeAGghLp8uJ/x4+AscDl7r4n8hkT6Q5310OPxB4EC5H/q4Pv\nXw2sA3oVn98MLAS+IJhR/88OXvOt4jHbCerfzwOnVXm8RwEvFT/jc+Ca0M9OIqjRDy0+Pwz4l+J/\nxxdAE/Dfij8bRtAuupOg3LOt+NopSf8/0SNfD3M/9E1DzOwJ4L8Dze4+oZNjHgUuA3YAN7t7Z90J\nIiISoyjlmieBSzv7oZldBox099HAVOBHVRqbiIj0UJch7+5vAZsPccgVwNPFY+cCg4o9vyIikrBq\nLLwOIah/lqwtfk9ERBKm7hoRkRyrxhWvawm6CkqGFr/XjpkdepVXREQ65O5WyeuizuSt+OjIbIr9\nzGZ2PvCFuzd39kZJtxOl5TFt2rTEx5CWh86FzkU9nIudO52333Yee8y55RZnwgSnf3/nrLOc225z\nHn/cefddZ9fKZvzrX8fHjsXfeQf3ns2Nu5zJm9nPgAbgaDNbRXCpdr8gr32Gu//SzP6kuN/IDuCW\nHo1IRCTjdu2CDz6AefMOPJYtg7Fj4Zxz4Lzz4Pbb4Ywz4PDDQy+cMwf+bArcdBM8+2zZDyvTZci7\n+3URjrmrxyMREcmgUqA3NR0I9OXLDwT6174Gd9wRBPphh3XxZiNGwCuvBC+qEu1CmZCGhoakh5Aa\nOhcH6FwckMZzsXNn+xn68uVw2mlBoJ9/Ptx5Z8RA78jw4cGjirq84rWqH2bmcX6eiEilygO9qQlW\nrDgQ6KVHxYHeDWaGV7jwqpAXkbpXCvRwySUc6JMmBb+OH1+FQHeHWbPgl7+En/400ksU8iIiEe3c\nCQsWHFxyWbECxo07eIZelUAvVygEBfqPP4annopce1fIi4h0oDzQm5rg009jCvSw0uz9nnuCzpkH\nHuhW54xCXkTq3o4d7Wfo4UAPl1z69Yt5cLNmwbRp3Zq9hynkRaSudBbop5/efoYee6B3pLUV2toq\n7ntXyItIbpUHelMTfPbZwYE+aVLwPBWBXgMKeRHJhe3b28/Qw4FeKrmkNtDdobkZvvrVqr6tQl5E\nMqezQB8//uCSS2oDvVypc2bzZnjzzaq+tUJeRFKtFOjhPvSVKzsuufTtm/Rou6mHnTNRKORFJDW2\nb4f33z94hl4K9FK5pTRDz1ygl6uw7727ehLy2rtGRCpWHuhNTbBq1YGSS0MDfOc7OQn0jixaBCNH\nVm3HyFrQTF5EIikFerjkEg70Usll3LicBnqCVK4Rkaratq19yWXVqmAzrvCiqAI9Hgp5EalYeaA3\nNcHq1Qr0gxQK8MYb8Bd/kcjHqyYvIpFs3dp+hh4O9IsvhnvvDXZfrNtADwt3ztx6a/DcKsraxGgm\nL5JTnQX6hAkHz9AV6J2IqXMmCpVrROpceaA3NcGaNe0Dfdw46KN/v3ftrbfgqqtq1vfeXQp5kTqy\ndSvMn3/wDD0c6KVe9NNOU6BXrFAILr9NcPYeppAXyanOAn3ixPYlFwV6finkRXJgy5b2fejr1nVc\nQ1eg1xeFvEjGbNnSfoYeDvRSyWXsWAV6zZQ6Z2bOhF/8ItVdMwp5kRQrD/SmJli/vn3JRYEeoxR1\nzkShkBdJiVKgh0su5YE+aVIQ6L17Jz3aOhTDjpG1oJAXScAXX7QvuYQDPVxyUaCnxGuvwd/8TSZm\n72EKeZEaKw/0pibYsAHOPLN9yUWBnmL79sGePZmYvYcp5EWqaPPm9jP05ub2JZdTT1WgSzwU8iIV\n6ijQSzP08A0uFOgZ4x7s4TBsWNIjqQqFvEgE5YHe1BQ0WZSXXBToGVfqnFm/PtieIMWtkVEp5EXK\nbN588Ox83rz2gT5pEowZo0DPjYx2zkShkJe6tmlT+5JLoQBnnXXwDF2BnmMZ63vvLu0nL3WjFOjh\nPvTf//5AoF9+eTCBU6DXmdWrYdSoVN9rNSmayUtqbdrUvuSycWP7ksvo0Qp0yTeVayTzOgv0jkou\nvXolPVqReCnkJVNaWtqXXFpaFOgSQaEAL70EU6cmPZJY1bwmb2aTgUeAXsAT7v5w2c8HAs8Cw4De\nwP9296cqGZDkS0tL+xl6ONCvvBJ+8IOg5KJAl06FO2duvjmT91pNSpczeTPrBSwFLgHWAe8B17r7\nktAx9wMD3f1+MzsG+AQ43t33lr2XZvI5Vh7oTU1BGebssw+eoSvQpVty3jkTRa1n8ucBy9x9ZfHD\nZgJXAEtCxzgwoPj1AKClPOAlXzZubD9D37xZM3SpsnffDVqmbrpJnTMVihLyQ4DVoedrCII/7DFg\ntpmtA44ErqnO8CQNugr0q66Chx4KOtgU6FJVY8fC7NlwXnnkSFTV6pO/FHjf3S82s5HAG2Y2wd23\nlx84ffr0/V83NDTQ0NBQpSFINZQHelNTsANjqeSiQJdYDRxYlwHf2NhIY2NjVd4rSk3+fGC6u08u\nPv8u4OHFVzN7FXjI3X9XfP4mcJ+7N5W9l2ryKfL737efoYcDvfRQoEsstJjaqZq2UJpZb4KF1EuA\n9cC7wBR3Xxw65l+Bgrs/YGbHA03ARHffVPZeCvmEdBXopR0XR45UoEvMSp0zM2bAG2/oN2AHat4n\nX2yh/GcOtFD+g5lNJZjRzzCzE4CngBOKL3nI3Z/v4H0U8jEoBXq4D33r1vYzdAW6JE6dM5HoYqg6\nVii0n6GXB/qkSTBihAJdUiTHO0bWgkK+TnQV6KWSiwJdUq+xEW6/XbP3iBTyOVQK9HDJZfv29iUX\nBbpkkntwr9XDDkt6JJmgkM+45ub2M/TyQC+VXNR8IFJ/FPIZUh7oTU2wY0cQ6OF7iirQJRfcYcWK\noA9XKqaQT6kNG9rP0HfsOLjcokCX3Cp1znz+Ocydq03/e0AhnwJRAn3SJDjlFAW65Jw6Z6pOIR+z\n8kBvaoJdu9rP0BXoUnfU914TusdrDa1f336GHg7066+Hf/onBboIEFxGPXq0doxMEc3kQ7oK9FLJ\n5eSTFegiEh+VaypQCvRwH/ru3Qd3uJxzjgJdRJKnkI/oxz+GV14JAv3LL9vX0BXoIhEVCvDMM/DX\nf60/NDFQyEewaxccfTQ8/XQwWx8+XL83RbqtvHPm7/9erZEx0MJrBB9+CKeeGtz0QkQqEO6ceeUV\ndc5kRN3sejJvXlCSEZEKLFgAEyYE+1O//74CPkPqZiY/f75CXqRiY8fCq68GtU7JFM3kRaRrhx+u\ngM+oulh43b0bBg+GTZt0fYZIl3Sv1dTpycJrXczkP/oIxoxRwIsckju88AL84R/C3r1Jj0aqpC5q\n8irViHShfM+ZPnURDXWhLmbyCnmRTpRm7+qcya26+Ot63jz45jeTHoVICs2bF2wFrL733Mr9wuuX\nX8JRR0FLC/TvH+tHi2TD3r0qz6ScFl4P4aOPgjuPKeBFOqGAz7Xch7zq8SIEtfdFi5IehSRAIS+S\nd4UCXH01TJkCra1Jj0ZippAXyatw58yoUcHNtPv2TXpUErNcL7yWFl03boQjjojtY0WSVyjA7bfD\n4sXw5JPqnMk4bTXciYULg9ZfBbzUnT17YNw4eO45Xepd53Id8irVSN0aOhT+9m+THoWkQK5r8gp5\nEal3CnmRLGtuhgcfhH37kh6JpFRuQ37PnqAt+Mwzkx6JSA2UOmcmToSdO6GtLekRSUrltia/cCGM\nGKFFV8mh5uZgx8jFi7XnjHQptzN53e5PcmnRomD2Pnp08JtcAS9dyO1MXvV4yaUxY+Df/111SIks\n0kzezCab2RIzW2pm93VyTIOZvW9mC81sTnWH2X0KecmlPn0U8NItXV7xama9gKXAJcA64D3gWndf\nEjpmEPD/gD9297Vmdoy7b+zgvWK54rW1Ff7gD4KL/r7ylZp/nEht7NsHvXJbUZVuqPVWw+cBy9x9\npbu3AjOBK8qOuQ540d3XAnQU8HH6+GMYPlwBLxlV6pw566zgLvQiPRClJj8EWB16voYg+MPGAH2L\nZZojgUfd/ZnqDLH7VKqRzCrtObNoUXCvVW1JID1UrX8L9gHOBi4DJgPfN7NRVXrvblPIS+aU7xip\ne61KlUSZya8FhoWeDy1+L2wNsNHddwO7zew/gYnA8vI3mz59+v6vGxoaaGho6N6II5g3L9g6WyQz\nFi8O9ppR37sAjY2NNDY2VuW9oiy89gY+IVh4XQ+8C0xx98WhY8YC/0Iwiz8MmAtc4+6Lyt6r5guv\npUXX5mY48siafpRIdbW1Qe/eSY9CUqimWw27e5uZ3QW8TlDeecLdF5vZ1ODHPsPdl5jZfwAfAm3A\njPKAj8uiRTBsmAJeMkgBLzWQu5uG/OQn8JvfwLPP1vRjRCq3YIF63aVbat1CmSladJXUKt1r9frr\nYdeupEcjdUIhLxKHWbOCzpkRI6CpCfr3T3pEUidyVa7ZuxcGDYING2DAgJp9jEh0GzcGfe8LFwZ9\n7+qckQroHq9FixbBSScp4CVFzOD00+GZZ3RhkyQiVyGvUo2kztFHQ+jaEJG45aomr5AXETmYQl6k\nGgoFuP/+YGFIJEVyE/J798KHHwYb94nEqtQ5s2+f7rUqqZObmvySJTB0KAwcmPRIpG4UCnDnnUHn\njPackZTKzUxepRqJ1YoVB/retWOkpFhuZvIKeYnViBHw61/D+PFJj0TkkHI1kz/77KRHIXXDTAEv\nmZCLK17b2oIrXdeuDX4VqSptASwJq/sNypYsgRNOUMBLDcyaBePGwfbtSY9EpCK5qMmrHi9VF+6c\nefpp3aBAMisXM3mFvFRVeMdIdc5IxuVmJn/FFUmPQnLh88/hBz9Q37vkRuYXXtvagnu6rl4d/CrS\nY+5B94xIStT1wusnn8DxxyvgpYoU8JIjmQ951eOlYnPnJj0CkZpTyEv9Kd1r9ZZbYOvWpEcjUlMK\neakv4c6Z+fO1o53kXqYXXkuLrqtWwVFHVe1tJY82bYKpU3WvVcmkur3H69KlcNxxCniJoF+/4GYD\nuteq1JlMh7xKNRLZkUfC976X9ChEYpfpmrxCXkTk0BTyki+FAnz727BrV9IjEUmFzIb8vn2wYIH2\nkJeQUufMYYfpgiaRoszW5Jctg6OPhsGDkx6JJE73WhXpVGZn8irVCBDcKUY7Rop0KrMzeYW8AHDi\nifDb38KppyY9EpFU0kxess1MAS9yCJm84nXfvuACqE8/DeryUidaW6Fv36RHIRK7uttqePnyIOQV\n8HVk1iwYMybYnkBEIstkTV6lmjoS7pyZOVPtVCLdlMmZvEK+TuheqyI9FinkzWyymS0xs6Vmdt8h\njjvXzFrN7MrqDbE9hXwd2LAB/vEfg773hx/WpmIiFepy4dXMegFLgUuAdcB7wLXuvqSD494AdgE/\ncfdfdPBePV54LS26rlgBxxzTo7eStNO9VkWA2i+8ngcsc/eV7t4KzASu6OC4bwE/BwqVDCSqFSuC\nPeQV8HVAAS/SY1FCfgiwOvR8TfF7+5nZicCfu/vjQE3/ZKpUk0O//W0waxeRqqvWwusjQLhWX7Og\nV8jnSOleq3/1V9DSkvRoRHIpSgvlWmBY6PnQ4vfCJgEzzcyAY4DLzKzV3WeXv9n06dP3f93Q0EBD\nQ0O3BjxvHtx7b7deImk0axbcfTfcdJPu1iRSprGxkcbGxqq8V5SF197AJwQLr+uBd4Ep7r64k+Of\nBP5PLRZe3YNF12XL4NhjK34bSdIXX8Bf/qXutSrSDTW9x6u7t5nZXcDrBOWdJ9x9sZlNDX7sM8pf\nUslAolixAgYOVMBnWv/+QbBr9i4Si0ztXfPCC8FFjy+9VMVBiYikXN3sXTN/vu4EJSLSHZkKeXXW\nZEihALffDlu2JD0SkbqWmZB3D2byCvkMKO05M3BgcL9VEUlMZnah/OwzOOIIOP74pEcindK9VkVS\nJzMzeZVqUq6lBSZO1I6RIimTmZm8Qj7ljj4a3n4bTj456ZGISIhm8lI9CniR1MlEn7x7MFFctAi+\n+tUaDEy6Z/duXcgkEqPc98l//nlwoaQCPgVmzYJRo2DduqRHIiIRZKImr1JNCoQ7Z158EU48MekR\niUgEmZjJK+QTpnutimRWZmbyd9+d9Cjq1ObN8Oij6nsXyajUL7y6B7f6W7gQTjihRgMTEUmxXC+8\nrlwZXBmvgBcR6b7Uh7zq8TF6/XXYty/pUYhIFSnk5cC9Vu+5BzZsSHo0IlJFCvl6V945o9ZIkVxJ\ndXeNexDyulFIDWzbBrfeqh0jRXIu1SG/ahX06aPJZU0ccQRcdJHutSqSc6kO+dJNQqyixiE5pN69\n4a67kh6FiNRYqmvyqseLiPSMQj7vCoWg9t7cnPRIRCQBqQ350qKrQr4HSp0zxx4LgwYlPRoRSUBq\na/Jr1gS1+CFDkh5JBuleqyJSlNqZfGkWr0XXbtq2Leg51Y6RIkKKZ/Iq1VRowACYO1f/BBIRIAMz\neamAAl5EilIZ8lp0jWjHjqRHICIpl8qQX7s2CPqhQ5MeSYqV7rX66adJj0REUiyVNXktuh5CuHPm\n5ZeDBVYRkU6kciavUk0ndK9VEemm1M7kb7st6VGkzI4d8G//pr53EemW1N3j1T241d+778KwYTEN\nTEQkxXJ1j9d166CtDU46KemRiIhkX+pCvnSTkLpedH31VdizJ+lRiEgOpK4mX9eLruHOmfHj4eST\nkx6RiGRcpJm8mU02syVmttTM7uvg59eZ2QfFx1tmdkalA6rbkC/vnFHAi0gVdLnwama9gKXAJcA6\n4D3gWndfEjrmfGCxu28xs8nAdHc/v4P36nLh9YQT4O236yjjdu6Em24KZu9PPaXOGRFpp9YLr+cB\ny9x9pbu3AjOBK8IHuPs77r6l+PQdoKLNU9avD0rRw4dX8uqM6t8fJk9W37uI1ESUkB8CrA49X8Oh\nQ/w24FeVDKYur3Q1g29+UzfTFpGaqOrCq5n9EXALcGFnx0yfPn3/1w0NDTQ0NOx/Xrf1eBGRkMbG\nRhobG6vyXlFq8ucT1NgnF59/F3B3f7jsuAnAi8Bkd1/RyXsdsiZ/+eVw441w1VXd+4/IhEIBvvMd\nePBBOOWUpEcjIhlS65r8e8AoMxtuZv2Aa4HZZQMYRhDwN3QW8FHkdiZf6pw58cRgZVlEJCZdlmvc\nvc3M7gJeJ/hL4Ql3X2xmU4Mf+wzg+8Bg4IdmZkCru5/XnYFs2AC7d+esq0b3WhWRhKVm75rXXoNH\nHoE33ohtOLW1ezeMHQvXXAMPPKCFVRGpWE/KNam54jV3pZrDDw92WTvuuKRHIiJ1LDV71+Qu5EEB\nLyKJU8hXw5YtXR8jIpKAVIR8c3NwdX/mOgvd4YUX4NRTg8VVEZGUSUVNPpPbCxcKcMcd8PHHQefM\n+PFJj0hEpJ1UzOQzVaopzd4nTIBRo7TnjIikWmpm8lOmJD2KiPbsgeeeU9+7iGRCKvrkTzoJ5swJ\nJsYiInKwTN/jtVCAbdtg5MikRyIikj+Jh3xqF13d4aWXYMeOpEciIlKxxGvyqVx0LXXOLFoEZ5yh\nOpKIZFYqZvKpCfnyzpn58xXwIpJpiS+8Dh8Ov/41jB4d2zA6tmcPXHddMHt/8kl1zohIamR2g7KN\nG4MdAVKx6NqvH3z96/Dss9oxUkRyI9GQnzcPzjoLeiVeNCrKTLO+iEg0icZrqurxIiI5VH8hXygE\nM/ZFi2L+YBGR+NVPyIc7Z4YPhxEjYvpgEZHkJFaTb2mBzZtj6lAM971rzxkRqSOJzeRjW3RtbYUL\nLjjQ966AF5E6kthMPrZSTd++wb1Wjzoqhg8TEUmXRGfysdXjFfAiUqfyFfKbNgULrCIiAiQU8i0t\nwaNqWxmUOmfGjYOmpiq9qYhI9iVSk58/H848s0qLruWdM+eeW4U3FRHJh0Rm8lUp1XS0Y6Q6Z0RE\nDpLITH7ePLjiih6+SVsbvPyy+t5FRA4hka2GR4yA116D006L7aNFRDKrJ1sNxx7yLS3O8OHwxRfQ\nu3dsHy0iklmZupF3adE1csC7w89/HrRHiohIt8Rek+/Womu4c2b8eBg8uKZjExHJm0Rm8l2GfEed\nM2PHxjI+EZE8SWQmP23aIQ5oawv2e1+4UJ0zIiI9FPvC65FHeteLrq+8ApdeqnutioiQse6aCy5w\n3norto8UEcm8mnfXmNlkM1tiZkvN7L5OjnnUzJaZ2QIzO7Oz99I9XUVE4tNlyJtZL+Ax4FLgdGCK\nmY0tO+YyYKS7jwamAj/q7P32h3yhAN/4RrDXex1qbGxMegipoXNxgM7FAToX1RFlJn8esMzdV7p7\nKzATKN+U4ArgaQB3nwsMMrPjO3qzc84Odc6MGBH8Wof0G/gAnYsDdC4O0LmojijdNUOA1aHnawiC\n/1DHrC1+r7n8zcZNuxoW616rIiJxiL2F0kaPgueeVeeMiEgMuuyuMbPzgenuPrn4/LuAu/vDoWN+\nBMxx9xeKz5cAF7l7c9l76bZNIiIVqLS7JspM/j1glJkNB9YD1wJTyo6ZDdwJvFD8S+GL8oDvySBF\nRKQyXYa8u7eZ2V3A6wQLtU+4+2Izmxr82Ge4+y/N7E/MbDmwA7iltsMWEZEoYr0YSkRE4lWTDcqq\nefFU1nV1LszsOjP7oPh4y8zOSGKccYjy+6J43Llm1mpmV8Y5vjhF/DPSYGbvm9lCM5sT9xjjEuHP\nyEAzm13Mio/M7OYEhllzZvaEmTWb2YeHOKb7uenuVX0Q/MWxHBgO9AUWAGPLjrkMeK349deAd6o9\njjQ8Ip6L84FBxa8n1/O5CB33JvAqcGXS407w98Ug4GNgSPH5MUmPO8FzcT/wUOk8AC1An6THXoNz\ncSFwJvBhJz+vKDdrMZOv6sVTGdfluXD3d9x9S/HpOwTXF+RRlN8XAN8Cfg4U4hxczKKci+uAF919\nLYC7b4x5jHGJci4cGFD8egDQ4u57YxxjLNz9LWDzIQ6pKDdrEfIdXTxVHlydXTyVN1HORdhtwK9q\nOqLkdHkuzOxE4M/d/XEgz51YUX5fjAEGm9kcM3vPzG6IbXTxinIuHgPGmdk64APgnpjGljYV5Wbs\nF0NJx8zsjwi6ki5MeiwJegQI12TzHPRd6QOcDVwMfAV428zedvflyQ4rEZcC77v7xWY2EnjDzCa4\n+/akB5YFtQj5tcCw0POhxe+VH3NSF8fkQZRzgZlNAGYAk939UP9cy7Io52ISMNPMjKD2epmZtbr7\n7JjGGJco52INsNHddwO7zew/gYkE9es8iXIubgEeAnD3FWb2GTAWaIplhOlRUW7Wolyz/+IpM+tH\ncPFU+R/S2cCNsP+K2g4vnsqBLs+FmQ0DXgRucPcVCYwxLl2eC3cfUXycQlCXvyOHAQ/R/oy8Alxo\nZr3N7AiChbbFMY8zDlHOxUrgvwIUa9BjgE9jHWV8jM7/BVtRblZ9Ju+6eGq/KOcC+D4wGPhhcQbb\n6u7lG8BlXsRzcdBLYh9kTCL+GVliZv8BfAi0ATPcfVGCw66JiL8v/g54KtRaeK+7b0poyDVjZj8D\nGoCjzWwVMA3oRw9zUxdDiYjkWE0uhhIRkXRQyIuI5JhCXkQkxxTyIiI5ppAXEckxhbyISI4p5EVE\nckwhLyKSY/8fC0hENbNts+4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb62ba6e050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Obtenemos la matriz de confusión para el conjunto de datos de prueba\n",
    "metricas_modelos(y_test, y_predic_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las áreas bajo la curva (AUC) tienen valores aceptables, y no difieren demasiado entre sí. Podemos considerar el modelo como bueno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQcAAADvCAYAAAD/yxH8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb62b883290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_predic_test)\n",
    "plt.matshow(cm)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('Real')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la matriz de confusion se puede ver que muchos mas acierto (TP) que del resto. El algoritmo acierta muy bien las muertes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sex_male', 'sibspX_n9', 'parchX_n9']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-2.29873152, -1.2650213 , -1.47757896]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print var_categoricas\n",
    "classifier.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La supervivencia de los pasajeros del Titanic dependió del sexo y de la clase en la que viajaban."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Algunos enlaces:\n",
    "- [Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic/data)\n",
    "- [Encyclopedia Titanica](https://www.encyclopedia-titanica.org/)\n",
    "- [Selección de variables explicativas en la regresión](https://jjgibaja.wordpress.com/2007/10/23/seleccion-de-variables-explicativas-en-la-regresion/)\n",
    "- [Scikit learn book](http://nbviewer.jupyter.org/github/gmonce/scikit-learn-book/tree/master/)\n",
    "- [Explaining Titanic Hypothesis with Decision Trees](http://nbviewer.jupyter.org/github/gmonce/scikit-learn-book/blob/master/Chapter%202%20-%20Supervised%20learning%20-%20Explaining%20Titanic%20Hypothesis%20with%20Decision%20Trees.ipynb)\n",
    "- [Introducción a scikit-learn](http://linuxec.es/grupo-python/sklearn/#)\n",
    "- [Sobreajuste - Overfitting](http://wwwae.ciemat.es/~cardenas/docs/lessons/sobreajuste.pdf)\n",
    "- [Integración y Adaptación de Modelos](http://users.dsic.upv.es/~jorallo/docent/master/t2.pdf)\n",
    "- [Getting Started with Kaggle Data Science Competitions](http://blogs.mathworks.com/loren/2015/06/18/getting-started-with-kaggle-data-science-competitions/)\n",
    "- [Machine Learning con Python](http://relopezbriega.github.io/blog/2015/10/10/machine-learning-con-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
